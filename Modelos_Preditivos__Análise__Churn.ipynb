{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwEE6ToO-C6R"
      },
      "source": [
        "# Modelos Preditivos da Análise de Churn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MutNAK2I-KoQ"
      },
      "source": [
        "## Contexto do Notebook\n",
        "\n",
        "Neste notebook, abordarei a modelagem de aprendizado de máquina. Meu principal objetivo é desenvolver um modelo capaz de prever com precisão a probabilidade de um funcionário deixar a empresa. Com esse modelo, a empresa poderá planejar estratégias de retenção de funcionários, garantindo uma receita estável. Vale ressaltar que a aquisição de novos funcionários é mais custosa do que manter os atuais. Além disso, detalharei cada etapa abaixo, explicando minhas decisões em cada passo.\n",
        "\n",
        "- ### Objetivo do Notebook\n",
        "\n",
        "O objetivo principal deste Notebook é construir um modelo de machine learning capaz de prever com precisão a probabilidade de churn de funcionários. Isso permitirá que a empresa identifique os funcionários com maior probabilidade de deixar a empresa e implemente estratégias de retenção específicas para esses casos, reduzindo assim a taxa de churn e mantendo uma equipe estável e produtiva.\n",
        "\n",
        "- ### Resultados Esperados\n",
        "\n",
        "Espera-se que, ao final deste Notebook, tenhamos um modelo de machine learning capaz de prever com precisão a probabilidade de churn de funcionários. Isso permitirá que a empresa implemente estratégias proativas de retenção de funcionários, reduzindo assim a taxa de churn e mantendo uma equipe estável e produtiva.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zKOvu3oFnp7"
      },
      "source": [
        "## Importação das bibliotecas e base de dados\n",
        "\n",
        "- Base de dados: https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização e Manipulação dos Dados\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Importação da base de dados\n",
        "base = pd.read_csv('/content/Human_Resources.csv')\n",
        "\n",
        "# Verificando quantos funcionários estão em Churn\n",
        "count_values = base['Attrition'].value_counts()\n",
        "\n",
        "# Calculando a porcentagem de Churn\n",
        "churn_percentage = (count_values[1] / len(base)) * 100\n",
        "\n",
        "# Mostrando os resultados de forma mais informativa\n",
        "print(f\"Total de funcionários na base de dados: {len(base)}\")\n",
        "print(f\"Quantidade de funcionários em churn (valores 1): {count_values[1]}\")\n",
        "print(f\"Quantidade de funcionários não em churn (valores 0): {count_values[0]}\")\n",
        "print(f\"Porcentagem de Churn: {churn_percentage:.2f}%\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iuos7du6D_ar",
        "outputId": "d46e3a47-b802-4444-9ebe-bcb4935c50e1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de funcionários na base de dados: 1470\n",
            "Quantidade de funcionários em churn (valores 1): 237\n",
            "Quantidade de funcionários não em churn (valores 0): 1233\n",
            "Porcentagem de Churn: 16.12%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A4IEFkKGOrw"
      },
      "source": [
        "É evidente que há um desequilíbrio entre os funcionários, com cerca de 16% deixando a empresa e 84% permanecendo. Diante disso, é necessário buscar modelos e métricas de avaliação apropriados para lidar com essa análise e desequilíbrio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqYQEwEFGB_b"
      },
      "source": [
        "## Realizando os Tratamentos Anteriores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformando dados categoricos binarios\n",
        "base['Attrition'] = base['Attrition'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "base['OverTime'] = base['OverTime'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "# Excluindo as colunas que não irão influenciar na análise\n",
        "base.drop(['EmployeeCount', 'StandardHours', 'Over18', 'EmployeeNumber'], axis=1, inplace=True)\n",
        "\n",
        "# Importando o OneHotEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Criando o encoder\n",
        "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore', dtype='int32')\n",
        "\n",
        "# Lista das colunas a serem transformadas\n",
        "columns_to_encode = ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus']\n",
        "\n",
        "# Iterando sobre as colunas e transformando-as\n",
        "for col in columns_to_encode:\n",
        "    ohe.fit(base[[col]])\n",
        "    ohe_df = pd.DataFrame(ohe.transform(base[[col]]), columns=ohe.get_feature_names_out())\n",
        "    base = pd.concat([base, ohe_df], axis=1)\n",
        "    base.drop([col], axis=1, inplace=True)\n",
        "\n",
        "# Verificando a base de dados resultante\n",
        "base.head()\n",
        "\n",
        "base.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az2iDfB2EDB3",
        "outputId": "2c630223-4343-43ab-9a56-9b4939ba3f37"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1470, 51)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Divisão entre treino/teste"
      ],
      "metadata": {
        "id": "DX85ssM-BIvh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "JEIGK-RbOoex"
      },
      "outputs": [],
      "source": [
        "# Separando previsores e a coluna alvo\n",
        "\n",
        "#Previsores\n",
        "X = base[['BusinessTravel_Non-Travel', 'BusinessTravel_Travel_Frequently',\n",
        "       'BusinessTravel_Travel_Rarely', 'Department_Human Resources',\n",
        "       'Department_Research & Development', 'Department_Sales',\n",
        "       'EducationField_Human Resources', 'EducationField_Life Sciences',\n",
        "       'EducationField_Marketing', 'EducationField_Medical',\n",
        "       'EducationField_Other', 'EducationField_Technical Degree',\n",
        "       'Gender_Female', 'Gender_Male', 'JobRole_Healthcare Representative',\n",
        "       'JobRole_Human Resources', 'JobRole_Laboratory Technician',\n",
        "       'JobRole_Manager', 'JobRole_Manufacturing Director',\n",
        "       'JobRole_Research Director', 'JobRole_Research Scientist',\n",
        "       'JobRole_Sales Executive', 'JobRole_Sales Representative',\n",
        "       'MaritalStatus_Divorced', 'MaritalStatus_Married',\n",
        "       'MaritalStatus_Single','Age', 'DailyRate', 'DistanceFromHome',\n",
        "       'Education', 'EnvironmentSatisfaction', 'HourlyRate', 'JobInvolvement',\n",
        "       'JobLevel', 'JobSatisfaction',\t'MonthlyIncome',\t'MonthlyRate',\t'NumCompaniesWorked',\t'OverTime',\n",
        "       'PercentSalaryHike', 'PerformanceRating',\t'RelationshipSatisfaction',\t'StockOptionLevel',\n",
        "       'TotalWorkingYears'\t,'TrainingTimesLastYear'\t, 'WorkLifeBalance',\t'YearsAtCompany',\n",
        "       'YearsInCurrentRole', 'YearsSinceLastPromotion',\t'YearsWithCurrManager']]\n",
        "\n",
        "#Coluna Alvo\n",
        "y = base['Attrition']\n",
        "\n",
        "#Normalizando os dados para que os algoritmos não considerem alguns atributos mais impotantes que outros:\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Separando em treino/teste:\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(X , y, test_size = 0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fYu2FLiI81b"
      },
      "source": [
        "Ao usar random_state=42, a divisão será sempre a mesma se usar o mesmo conjunto de dados X e y e manter o random_state como 42 em todas as chamadas de train_test_split. Se você alterar o valor de random_state, a divisão será diferente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzFlWEdaPQQ3"
      },
      "source": [
        "## Criação de Modelos\n",
        "\n",
        "Modelos Escolhidos:\n",
        "- Regressão Logística\n",
        "- Random Forest\n",
        "\n",
        "Esses modelos foram escolhidos por sua capacidade de lidar com classes desbalanceadas e por sua eficácia em problemas de classificação, como é o caso da preisão de Churn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDObdy9NFDeO"
      },
      "source": [
        "#### Importação das Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KZOqyWSpFJzs"
      },
      "outputs": [],
      "source": [
        "# Importação do modelo de regressão logística\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Importação do modelo de classificação de Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Importação das métricas de avaliação de modelos\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2YaGTY1PJWf"
      },
      "source": [
        "#### Regressão Logística"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIr1IXjtQBmE"
      },
      "source": [
        "Optei por testar a regressão logística para modelar o churn dos funcionários pois:\n",
        "\n",
        "1. Adequação à Variável de Resposta: A regressão logística é ideal para problemas em que a variável de resposta é binária, como é o caso do churn de funcionários, em que eles podem ou não deixar a empresa.\n",
        "\n",
        "2. Interpretabilidade dos Resultados: A regressão logística oferece uma interpretação direta dos coeficientes como log-odds, o que significa que podemos entender facilmente o impacto de cada variável de entrada na probabilidade de churn de um funcionário.\n",
        "\n",
        "3. Simplicidade e Eficiência: Este modelo é relativamente simples de implementar e computacionalmente eficiente para conjuntos de dados de tamanho moderado, como o nosso, facilitando a interpretação e aplicação prática dos resultados.\n",
        "\n",
        "4. Tratamento do Desbalanceamento de Classes: A regressão logística pode lidar efetivamente com desbalanceamento de classes, uma vez que existem técnicas específicas, como a ponderação de classes ou o ajuste de limiares de decisão, que podem ser aplicadas para melhorar o desempenho do modelo nesse contexto.\n",
        "\n",
        "Portanto, a escolha da regressão logística é fundamentada em sua capacidade de lidar com a natureza binária da variável de resposta, sua interpretabilidade direta, eficiência computacional e capacidade de tratar o **desbalanceamento** de classes, tornando-a uma escolha sólida para nosso problema de modelagem de churn de funcionários."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "7ZZrvQ1qQ-ZG",
        "outputId": "50af119c-ba64-40f6-d31f-891cdfc3ea38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Criando o modelo de regressão logística\n",
        "reg_log = LogisticRegression(random_state=42)\n",
        "\n",
        "# Treinando o modelo\n",
        "reg_log.fit(X_treino, y_treino)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "VznLH-pnRDpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ba408d6-162a-4345-e3cd-934223c63b66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Fazendo a previsão\n",
        "y_pred_rl = reg_log.predict(X_teste)\n",
        "y_pred_rl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrLdC7AOxIHr"
      },
      "source": [
        "##### Métodos de Avaliação Regressão Logística:\n",
        "\n",
        "Uma matriz de confusão é uma tabela que é usada para descrever o desempenho de um modelo de classificação em um conjunto de dados de teste para os quais os rótulos verdadeiros são conhecidos. A ideia é contar o número de vezes que cada classe real foi classificada como cada classe prevista pelo modelo. As entradas na matriz de confusão são divididas em quatro categorias:\n",
        "\n",
        "[[TN, FP]\n",
        "\n",
        "[FN, TP]]\n",
        "\n",
        "Sendo:\n",
        "\n",
        "- **Verdadeiro positivo (TP)**: Representa os casos em que o modelo previu corretamente que um cliente iria sair (churn) e de fato ele saiu. São importantes para entendermos a capacidade do modelo em identificar corretamente os casos positivos, ou seja, os clientes que realmente estão propensos a sair.\n",
        "\n",
        "- **Falso positivo (FP)**: Indica os casos em que o modelo previu erroneamente que um cliente iria sair (churn), mas na verdade ele não saiu. Esses casos são relevantes, pois representam clientes que podem ser erroneamente identificados como propensos a sair, o que pode resultar em estratégias inadequadas de retenção de clientes.\n",
        "\n",
        "- **Verdadeiro negativo (TN)**: São os casos em que o modelo previu corretamente que um cliente não iria sair (não churn) e de fato ele não saiu. Esses casos são importantes para entendermos a capacidade do modelo em identificar corretamente os casos negativos, ou seja, os clientes que não estão propensos a sair.\n",
        "\n",
        "- **Falso negativo (FN)**: Representa os casos em que o modelo previu erroneamente que um cliente não iria sair (não churn), mas na verdade ele saiu. Esses casos são críticos, pois indicam clientes que foram erroneamente considerados como não propensos a sair, o que pode resultar em perda de oportunidades de retenção.\n",
        "\n",
        "Na análise de Churn, essas classificações são usadas para calcular diversas métricas de avaliação do modelo, tais como precisão, recall, pontuação F1 e taxa de erro. Essas métricas ajudam a avaliar o desempenho do modelo em identificar corretamente os clientes propensos a sair (Churn) e os clientes não propensos a sair, fornecendo insights valiosos para ações de retenção de clientes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MbeMoO0nScJZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8616629d-3292-435e-e0ec-29805a6f9caf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[311,   9],\n",
              "       [ 29,  19]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Calculando a matriz de confusão para avaliar o desempenho do modelo\n",
        "cm = confusion_matrix(y_teste, y_pred_rl)\n",
        "cm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0HOEQS_z4Yb"
      },
      "source": [
        "Analisando a Matriz de Confusão:\n",
        "\n",
        "- Verdadeiros Positivos (TP): 19\n",
        "- Falsos Positivos (FP): 9\n",
        "- Verdadeiros Negativos (TN): 311\n",
        "- Falsos Negativos (FN): 29\n",
        "\n",
        "Com esses valores, podemos calcular as seguintes métricas:\n",
        "\n",
        "- Precisão: A precisão é a proporção de verdadeiros positivos em relação a todos os casos positivos previstos pelo modelo. É calculada como TP / (TP + FP). Neste caso, a precisão é 19 / (19 + 9) ≈ 0.68, ou 68%.\n",
        "\n",
        "- Recall (Sensibilidade): O recall é a proporção de verdadeiros positivos em relação a todos os casos positivos reais. É calculado como TP / (TP + FN). Neste caso, o recall é 19 / (20 + 29) ≈ 0.4, ou aproximadamente 40%.\n",
        "\n",
        "- F1-score(avg): O F1-score é a média harmônica da precisão e do recall e fornece um equilíbrio entre os dois. É calculado como 2 * (precisão * recall) / (precisão + recall). Neste caso, o F1-score é aproximadamente 0.72, ou 72%.\n",
        "\n",
        "- Acurácia: A acurácia é a proporção de predições corretas em relação ao total de predições. É calculada como (TP + TN) / (TP + FP + TN + FN). Neste caso, a acurácia é (19 + 311) / (19 + 9 + 311+ 29) ≈ 0.90, ou aproximadamente 90%.\n",
        "\n",
        "Essas métricas fornecem uma visão abrangente do desempenho do modelo de regressão logística na análise de churn. Em geral, parece que o modelo tem uma precisão bastante alta, mas um recall relativamente baixo, o que significa que ele pode estar identificando corretamente muitos dos casos de churn, mas também está perdendo alguns casos que deveriam ser identificados. Dependendo dos objetivos específicos da análise de churn, pode ser necessário ajustar o modelo para melhorar o recall ou outras métricas importantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ4CrSyIz6cM"
      },
      "source": [
        "Agora, irei gerar um relatório contendo essas métricas de avaliação e espera-se que os resultados estejam em conformidade com os cálculos realizados anteriormente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXIt7a47x-Aq"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0mQ9bhzVsvM",
        "outputId": "83c623a6-c4de-4e76-8ff2-c2b234409064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.97      0.94       320\n",
            "           1       0.68      0.40      0.50        48\n",
            "\n",
            "    accuracy                           0.90       368\n",
            "   macro avg       0.80      0.68      0.72       368\n",
            "weighted avg       0.88      0.90      0.88       368\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Relatório de Métricas\n",
        "print(classification_report(y_teste, y_pred_rl))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hmx_QEGa0ulM"
      },
      "source": [
        "Como podemos notar, os resultados estão de acordo com os cálculos feitos anteriormente:\n",
        "\n",
        "Relatório de análise de churn utilizando um modelo de Regressão Logística:\n",
        "\n",
        "Os resultados da análise de churn utilizando o modelo Random Forest são apresentados a seguir:\n",
        "\n",
        "**Para a classe 0 (funcionários que não deixaram a empresa):**\n",
        "\n",
        "- A precisão é de 91%, indicando que 91% das previsões feitas para a classe 0 estão corretas.\n",
        "- O recall é de 97%, o que significa que o modelo identificou corretamente 97% dos casos da classe 0.\n",
        "- O F1-score é de 94%, uma métrica que representa a média harmônica entre precisão e recall, útil para avaliar o equilíbrio entre essas métricas.\n",
        "\n",
        "**Para a classe 1 (funcionários que deixaram a empresa):**\n",
        "\n",
        "- A precisão é de 80%, o que significa que 80% das previsões feitas para a classe 1 estão corretas.\n",
        "- O recall é de 40%, indicando que o modelo identificou corretamente apenas 40% dos casos da classe 1.\n",
        "- O F1-score é de 50%.\n",
        "- A acurácia geral do modelo é de 90%, o que significa que ele classificou corretamente 90% dos exemplos.\n",
        "\n",
        "A média ponderada das métricas (precisão, recall e F1-score) considerando o suporte de cada classe é de 88%, o que representa uma avaliação geral do modelo para ambas as classes, levando em conta o desbalanceamento entre elas.\n",
        "\n",
        "Essas métricas fornecem uma visão abrangente do desempenho do modelo de Random Forest na análise de churn. Enquanto a precisão e o recall para a classe 0 são altos, para a classe 1, a precisão é razoável, mas o recall é baixo, indicando que o modelo pode estar tendo dificuldades em identificar corretamente os casos de churn. Sugere-se a exploração de outros modelos que possam fornecer um melhor desempenho de previsão."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSYDaNdu1Jrd"
      },
      "source": [
        "Dessa forma, podemos notar que a acurácia, por si só, pode não ser uma boa métrica de avaliação para análise da saída de funcionários em casos onde apenas 16% dos funcionários deixam a empresa. Em um conjunto de dados desbalanceado como esse, um modelo pode atingir uma alta acurácia simplesmente prevendo a classe majoritária na maioria dos casos, ignorando completamente a classe minoritária. Isso ocorre porque a acurácia pode ser enganosa e não refletir a capacidade real do modelo de identificar os funcionários que saem da empresa.\n",
        "\n",
        "Por outro lado, o recall e o F1-score são métricas mais adequadas para avaliar a efetividade do modelo de churn em um cenário desbalanceado. O recall, também conhecido como sensibilidade, mede a capacidade do modelo de identificar corretamente todos os casos positivos (Churn, neste caso) no conjunto de dados. Um recall baixo indicaria que o modelo está deixando de identificar muitos casos de churn, o que não é desejável em uma análise de churn.\n",
        "\n",
        "O F1-score, que é a média harmônica entre precisão e recall, fornece um equilíbrio entre essas duas métricas. Ele é especialmente útil em conjuntos de dados desbalanceados, pois considera tanto a capacidade do modelo de identificar corretamente os casos positivos quanto a sua capacidade de evitar falsos positivos.\n",
        "\n",
        "Portanto, em uma análise de Churn, é importante considerar métricas como recall e F1-score, que levam em conta a natureza desbalanceada do problema e fornecem uma avaliação mais precisa da efetividade do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjKcK74P3cSF"
      },
      "source": [
        "Vou criar um DataFrame para armazenar as métricas de avaliação mais relevantes para uma análise de Churn: recall e F1-score. Posterormente irei atualizar esse DataFrame para comparar melhor outros tipos de modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72zPba682Fks",
        "outputId": "7d455366-a46a-4da3-8de7-6a55ced0f0fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     recall_0  recall_1  f1_score_0  f1_score_1\n",
            "regressao_logistica      0.97       0.4        0.94         0.5\n"
          ]
        }
      ],
      "source": [
        "# Definir os dados do classification_report\n",
        "data = {\n",
        "    'recall_0': [0.97],\n",
        "    'recall_1': [0.40],\n",
        "    'f1_score_0': [0.94],\n",
        "    'f1_score_1': [0.50]\n",
        "}\n",
        "\n",
        "# Criar o DataFrame\n",
        "desempenho_modelos = pd.DataFrame(data, index=['regressao_logistica'])\n",
        "\n",
        "# Exibir o DataFrame\n",
        "print(desempenho_modelos)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iey5LWwkWei0"
      },
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hd1zhAMxW8gJ"
      },
      "source": [
        "Agora, com um entendimento mais robusto sobre as métricas de avaliação e interpretação dessas métricas, vou proceder com o teste do modelo Random Forest para modelar o Churn dos funcionários, motivado pelas seguintes razões principais:\n",
        "\n",
        "1. Capacidade de Lidar com Dados Não Lineares: O Random Forest é capaz de capturar relações não lineares entre as variáveis de entrada e a variável de saída, o que é crucial em problemas complexos como a previsão de churn de funcionários, onde as interações entre os fatores podem ser não triviais.\n",
        "\n",
        "2. Redução do Overfitting: O Random Forest tende a ter um desempenho melhor do que modelos lineares quando há uma grande quantidade de variáveis de entrada, pois ele seleciona aleatoriamente subconjuntos das variáveis em cada divisão da árvore, o que ajuda a reduzir o overfitting (quando um modelo se ajusta muito bem aos dados de treinamento, mas não consegue generalizar para novos dados, resultando em um desempenho inferior).\n",
        "\n",
        "3. Robustez a Valores Ausentes e Outliers: O Random Forest é robusto a valores ausentes e outliers, o que é importante em conjuntos de dados do mundo real, onde esses problemas são comuns e podem prejudicar o desempenho de outros modelos.\n",
        "\n",
        "4. Facilidade de Uso e Implementação: O Random Forest é relativamente simples de usar e não requer muitos ajustes de parâmetros para obter um bom desempenho, o que facilita sua implementação prática em nosso cenário.\n",
        "\n",
        "5. Capacidade de Lidar com Desequilíbrio de Classes: O Random Forest pode lidar naturalmente com desequilíbrios de classes, como o que temos em nosso conjunto de dados, onde apenas cerca de 16% dos funcionários apresentam churn.\n",
        "\n",
        "Portanto, a escolha do Random Forest é baseada em sua capacidade de lidar com relações não lineares, reduzir o overfitting, robustez a valores ausentes e outliers, facilidade de uso e implementação, e capacidade de lidar com **desequilíbrios de classes**, tornando-o uma escolha sólida e adequada para nosso problema de modelagem de churn de funcionários.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "Tqlh2VQ0bINd",
        "outputId": "b4dc222e-c563-46af-a9a2-99281003e731"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Criando o modelo de classificação por florestas aleatórias\n",
        "forest = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Treinando o modelo\n",
        "forest.fit(X_treino, y_treino)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "EeTFnz1LbKud"
      },
      "outputs": [],
      "source": [
        "#Fazendo a previsão\n",
        "y_pred_rf = forest.predict(X_teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJLbYVDVbNqX",
        "outputId": "13982198-6471-448f-bc11-350e3ddeabbe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[317,  45],\n",
              "       [  3,   3]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# Calculando a matriz de confusão para avaliar o desempenho do modelo\n",
        "cm_rf = confusion_matrix(y_pred_rf, y_teste)\n",
        "cm_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icV5wnshoqPK",
        "outputId": "c185fddc-2d30-48dd-927b-f55e2111f8d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.99      0.93       320\n",
            "           1       0.50      0.06      0.11        48\n",
            "\n",
            "    accuracy                           0.87       368\n",
            "   macro avg       0.69      0.53      0.52       368\n",
            "weighted avg       0.83      0.87      0.82       368\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Relatório de Métricas\n",
        "print(classification_report(y_teste, y_pred_rf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZlr-EV8Zuzs"
      },
      "source": [
        "##### Métodos de Avaliação Random Forest:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqb_p0qo82lZ"
      },
      "source": [
        "Relatório de análise de churn utilizando um modelo Random Forest:\n",
        "\n",
        "Os resultados da análise de churn utilizando o modelo Random Forest são apresentados a seguir:\n",
        "\n",
        "**Para a classe 0 ((funcionários que não deixaram a empresa)):**\n",
        "\n",
        "- A precisão é de 88%, indicando que 88% das previsões feitas para a classe 0 estão corretas.\n",
        "- O recall é de 99%, o que significa que o modelo identificou corretamente 99% dos casos da classe 0.\n",
        "- O F1-score é de 93%, uma métrica que representa a média harmônica entre precisão e recall, útil para avaliar o equilíbrio entre essas métricas.\n",
        "\n",
        "**Para a classe 1 ((funcionários que deixaram a empresa))**:\n",
        "\n",
        "- A precisão é de 50%, o que significa que 50% das previsões feitas para a classe 1 estão corretas.\n",
        "- O recall é de 6%, indicando que o modelo identificou corretamente apenas 6% dos casos da classe 1.\n",
        "- O F1-score é de 11%.\n",
        "- A acurácia geral do modelo é de 87%, o que significa que ele classificou corretamente 87% dos exemplos.\n",
        "\n",
        "A média ponderada das métricas (precisão, recall e F1-score) considerando o suporte de cada classe é de 83%, o que representa uma avaliação geral do modelo para ambas as classes, levando em conta o desbalanceamento entre elas.\n",
        "\n",
        "Essas métricas fornecem uma visão abrangente do desempenho do modelo de Random Forest na análise de churn. Em geral, a precisão e o recall para a classe 1(funcionários que deixaram a empresa) são baixos, o que indica que o modelo pode estar tendo dificuldades em identificar corretamente os casos de churn. Sugere-se a exploração de outros modelos que possam fornecer um melhor desempenho de previsão."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBy_7suw92Ti",
        "outputId": "a4ac92d5-99f8-4f1c-c102-92308049619e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     recall_0  recall_1  f1_score_0  f1_score_1\n",
            "regressao_logistica      0.97      0.40        0.94        0.50\n",
            "random_forest            0.99      0.06        0.93        0.11\n"
          ]
        }
      ],
      "source": [
        "# Atualizando o DataFrame de desempenho\n",
        "data_random_forest = {\n",
        "    'recall_0': 0.99,\n",
        "    'recall_1': 0.06,\n",
        "    'f1_score_0': 0.93,\n",
        "    'f1_score_1': 0.11\n",
        "}\n",
        "\n",
        "\n",
        "desempenho_modelos.loc['random_forest'] = data_random_forest\n",
        "\n",
        "# Exibir o DataFrame atualizado\n",
        "print(desempenho_modelos)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outros Modelos"
      ],
      "metadata": {
        "id": "1rsk4sF891DS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AdaBoost: Um algoritmo de boosting que pode ser eficaz para melhorar a performance em conjuntos de dados desbalanceados, dando mais peso às instâncias da classe minoritária."
      ],
      "metadata": {
        "id": "1t_rYHkoDcwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# Criando o modelo de AdaBoost\n",
        "adaboost = AdaBoostClassifier()\n",
        "\n",
        "# Treinando o modelo\n",
        "adaboost.fit(X_treino, y_treino)\n",
        "\n",
        "# Fazendo previsões\n",
        "y_pred = adaboost.predict(X_teste)\n",
        "\n",
        "\n",
        "# Exibindo o relatório de classificação\n",
        "print(classification_report(y_teste, y_pred))\n",
        "\n",
        "# Matriz de Confusão\n",
        "cm = confusion_matrix(y_pred, y_teste)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOG5ZKsx9222",
        "outputId": "27cb4264-d359-4a1b-b963-2b5a1ee426ab"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92       320\n",
            "           1       0.47      0.33      0.39        48\n",
            "\n",
            "    accuracy                           0.86       368\n",
            "   macro avg       0.69      0.64      0.66       368\n",
            "weighted avg       0.85      0.86      0.85       368\n",
            "\n",
            "[[302  32]\n",
            " [ 18  16]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost: Esse algoritmo de gradient boosting que geralmente apresenta ótima performance em conjuntos de dados desbalanceados, mas pode exigir um pouco mais de ajuste de hiperparâmetros."
      ],
      "metadata": {
        "id": "ctO8ZI6-De3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Criando o modelo XGBoost\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Treinando o modelo\n",
        "xgb.fit(X_treino, y_treino)\n",
        "\n",
        "# Fazendo previsões\n",
        "y_pred = xgb.predict(X_teste)\n",
        "\n",
        "# Exibindo o relatório de classificação\n",
        "print(classification_report(y_teste, y_pred))\n",
        "\n",
        "# Matriz de Confusão\n",
        "cm = confusion_matrix(y_pred, y_teste)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZbnMQjB9275",
        "outputId": "ee5db122-5fde-4293-9c1f-96eaf08aeb50"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.97      0.94       320\n",
            "           1       0.62      0.31      0.42        48\n",
            "\n",
            "    accuracy                           0.89       368\n",
            "   macro avg       0.76      0.64      0.68       368\n",
            "weighted avg       0.87      0.89      0.87       368\n",
            "\n",
            "[[311  33]\n",
            " [  9  15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM (Support Vector Machines): O SVM pode ser eficaz para problemas de classificação binária como churn, especialmente com kernels apropriados."
      ],
      "metadata": {
        "id": "WP5heJwqDmpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Criando o modelo SVM\n",
        "svm = SVC()\n",
        "\n",
        "# Treinando o modelo\n",
        "svm.fit(X_treino, y_treino)\n",
        "\n",
        "# Fazendo previsões\n",
        "y_pred = svm.predict(X_teste)\n",
        "\n",
        "# Exibindo o relatório de classificação\n",
        "print(classification_report(y_teste, y_pred))\n",
        "\n",
        "# Matriz de Confusão\n",
        "cm = confusion_matrix(y_pred, y_teste)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1dii_TU92_j",
        "outputId": "8adbaec7-3825-4979-e0ee-1b085e1e5198"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.99      0.95       320\n",
            "           1       0.87      0.27      0.41        48\n",
            "\n",
            "    accuracy                           0.90       368\n",
            "   macro avg       0.88      0.63      0.68       368\n",
            "weighted avg       0.90      0.90      0.88       368\n",
            "\n",
            "[[318  35]\n",
            " [  2  13]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN (K-Nearest Neighbors): O KNN é um modelo simples que pode ser eficaz para detectar padrões em conjuntos de dados desbalanceados."
      ],
      "metadata": {
        "id": "kb4iQkUgDuVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Criando o modelo KNN\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Treinando o modelo\n",
        "knn.fit(X_treino, y_treino)\n",
        "\n",
        "# Fazendo previsões\n",
        "y_pred = knn.predict(X_teste)\n",
        "\n",
        "# Exibindo o relatório de classificação\n",
        "print(classification_report(y_teste, y_pred))\n",
        "\n",
        "# Matriz de Confusão\n",
        "cm = confusion_matrix(y_pred, y_teste)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMfugDMw93DL",
        "outputId": "8f5a5ddb-8f28-473e-e373-b48577f08f2c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.99      0.94       320\n",
            "           1       0.77      0.21      0.33        48\n",
            "\n",
            "    accuracy                           0.89       368\n",
            "   macro avg       0.83      0.60      0.63       368\n",
            "weighted avg       0.88      0.89      0.86       368\n",
            "\n",
            "[[317  38]\n",
            " [  3  10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes: O Naive Bayes é um modelo probabilístico simples que pode funcionar bem em conjuntos de dados desbalanceados. Embora não seja tão complexo, pode ser eficaz para aumentar o recall."
      ],
      "metadata": {
        "id": "5xEYXqTLDyFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Criando o modelo Naive Bayes\n",
        "nb = GaussianNB()\n",
        "\n",
        "# Treinando o modelo\n",
        "nb.fit(X_treino, y_treino)\n",
        "\n",
        "# Fazendo previsões\n",
        "y_pred = nb.predict(X_teste)\n",
        "\n",
        "# Exibindo o relatório de classificação\n",
        "print(classification_report(y_teste, y_pred))\n",
        "\n",
        "# Matriz de Confusão\n",
        "cm = confusion_matrix(y_pred, y_teste)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzewEHMy_Ioa",
        "outputId": "4055fea5-1d51-4c25-ab4f-3be41336a548"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.68      0.78       320\n",
            "           1       0.22      0.60      0.32        48\n",
            "\n",
            "    accuracy                           0.67       368\n",
            "   macro avg       0.57      0.64      0.55       368\n",
            "weighted avg       0.83      0.67      0.72       368\n",
            "\n",
            "[[218  19]\n",
            " [102  29]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Atualizarei a tabela de desempenho dos modelos preditivos"
      ],
      "metadata": {
        "id": "zvhuRla4D4_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Atualizando o DataFrame de desempenho\n",
        "\n",
        "data_adaboost = {\n",
        "    'recall_0': 0.94,\n",
        "    'recall_1': 0.33,\n",
        "    'f1_score_0': 0.92,\n",
        "    'f1_score_1': 0.39\n",
        "}\n",
        "\n",
        "\n",
        "desempenho_modelos.loc['adaboost'] = data_adaboost\n",
        "\n",
        "data_xgb = {\n",
        "    'recall_0': 0.97,\n",
        "    'recall_1': 0.31,\n",
        "    'f1_score_0': 0.94,\n",
        "    'f1_score_1': 0.42\n",
        "}\n",
        "\n",
        "\n",
        "desempenho_modelos.loc['xgb'] = data_xgb\n",
        "\n",
        "\n",
        "data_svm = {\n",
        "    'recall_0': 0.99,\n",
        "    'recall_1': 0.27,\n",
        "    'f1_score_0': 0.95,\n",
        "    'f1_score_1': 0.41\n",
        "}\n",
        "\n",
        "\n",
        "desempenho_modelos.loc['svm'] = data_svm\n",
        "\n",
        "data_knn = {\n",
        "    'recall_0': 0.99,\n",
        "    'recall_1': 0.21,\n",
        "    'f1_score_0': 0.94,\n",
        "    'f1_score_1': 0.33\n",
        "}\n",
        "\n",
        "\n",
        "desempenho_modelos.loc['knn'] = data_knn\n",
        "\n",
        "data_nb = {\n",
        "    'recall_0': 0.68,\n",
        "    'recall_1': 0.60,\n",
        "    'f1_score_0': 0.78,\n",
        "    'f1_score_1': 0.32\n",
        "}\n",
        "\n",
        "\n",
        "desempenho_modelos.loc['nb'] = data_nb\n",
        "\n",
        "\n",
        "\n",
        "# Exibir o DataFrame atualizado\n",
        "print(desempenho_modelos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpGMUiQ793Hx",
        "outputId": "361cc714-6376-47e0-c84b-94d07c4a680b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     recall_0  recall_1  f1_score_0  f1_score_1\n",
            "regressao_logistica      0.97      0.40        0.94        0.50\n",
            "random_forest            0.99      0.06        0.93        0.11\n",
            "adaboost                 0.94      0.33        0.92        0.39\n",
            "xgb                      0.97      0.31        0.94        0.42\n",
            "svm                      0.99      0.27        0.95        0.41\n",
            "knn                      0.99      0.21        0.94        0.33\n",
            "nb                       0.68      0.60        0.78        0.32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylqdrEh8Rv6W"
      },
      "source": [
        "### Relatório dos Modelos\n",
        "\n",
        "**Regressão Logística:**\n",
        "\n",
        "- Recall Classe 0: 0.97\n",
        "- Recall Classe 1 (Churn): 0.40\n",
        "- F1-Score Classe 0: 0.94\n",
        "- F1-Score Classe 1 (Churn): 0.50\n",
        "\n",
        "**Random Forest:**\n",
        "\n",
        "- Recall Classe 0: 0.99\n",
        "- Recall Classe 1 (Churn): 0.06\n",
        "- F1-Score Classe 0: 0.93\n",
        "- F1-Score Classe 1 (Churn): 0.11\n",
        "\n",
        "**AdaBoost:**\n",
        "\n",
        "- Recall Classe 0: 0.94\n",
        "- Recall Classe 1 (Churn): 0.33\n",
        "- F1-Score Classe 0: 0.92\n",
        "- F1-Score Classe 1 (Churn): 0.39\n",
        "\n",
        "**XGBoost:**\n",
        "\n",
        "- Recall Classe 0: 0.97\n",
        "- Recall Classe 1 (Churn): 0.31\n",
        "- F1-Score Classe 0: 0.94\n",
        "- F1-Score Classe 1 (Churn): 0.42\n",
        "\n",
        "**SVM:**\n",
        "\n",
        "- Recall Classe 0: 0.99\n",
        "- Recall Classe 1 (Churn): 0.27\n",
        "- F1-Score Classe 0: 0.95\n",
        "- F1-Score Classe 1 (Churn): 0.41\n",
        "\n",
        "**KNN:**\n",
        "\n",
        "- Recall Classe 0: 0.99\n",
        "- Recall Classe 1 (Churn): 0.21\n",
        "- F1-Score Classe 0: 0.94\n",
        "- F1-Score Classe 1 (Churn): 0.33\n",
        "\n",
        "**Naive Bayes:**\n",
        "\n",
        "- Recall Classe 0: 0.68\n",
        "- Recall Classe 1 (Churn): 0.60\n",
        "- F1-Score Classe 0: 0.78\n",
        "- F1-Score Classe 1 (Churn): 0.32\n",
        "\n",
        "**Conclusão e Próximos Passos:**\n",
        "\n",
        "Com base na análise dos resultados, os algoritmos que se destacam são a Regressão Logística e o XGBoost. Ambos apresentaram um bom equilíbrio entre recall e f1-score para a classe de interesse (churn).\n",
        "\n",
        "Considerando a simplicidade e interpretabilidade da Regressão Logística, ela será uma boa opção para tentar otimizar inicialmente. Já o XGBoost, apesar de ser mais complexo, também mostrou um bom desempenho e capacidade de lidar com conjuntos de dados desbalanceados, sendo outra opção promissora para otimização.\n",
        "\n",
        "O próximo passo será realizar a otimizção dos modelos. Usarei técnicas como balanceamento de classes e seleção de atributos para melhorar ainda mais seu desempenho na identificação de casos de churn. Essa otimização está contida nesse [notebook]()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}